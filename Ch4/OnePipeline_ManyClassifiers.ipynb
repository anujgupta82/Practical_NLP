{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Notebook_1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nishkalavallabhi/practicalnlp/blob/master/Ch4/Ch4-Latest/Notebook_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "janWv1vG5xUD",
        "colab_type": "text"
      },
      "source": [
        "# *Chapter-4: Text Classification with Naive Bayes, Logistic Regression, SVM*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBCjEALX5xWj",
        "colab_type": "text"
      },
      "source": [
        "**Overview:** This notebook aims to give you a brief overview of performing text classification using Naive Bayes, Logistic Regression and Support Vector Machines. We will be using a dataset called \"Economic news article tone and relevance\" from Figure-Eight (https://www.figure-eight.com/data-for-everyone/) which consists of approximately 8000 news articles, which were tagged as relevant or not relevant to the US Economy. Our goal in this notebook is to explore the process of training and testing text classifiers for this problem, using this data set and two text classification algorithms: Multinomial Naive Bayes and Logistic Regression, implemented in sklearn. \n",
        "\n",
        "##### Dataset Link: https://d1p17r2m4rzlbo.cloudfront.net/wp-content/uploads/2016/03/Full-Economic-News-DFE-839861.csv\n",
        "\n",
        "Let's import few necessary packages before we start our work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBvvarqE5xWm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "73b3d0e2-1665-410b-e5c3-d260a81662d5"
      },
      "source": [
        "import pandas as pd #to work with csv files\n",
        "\n",
        "#matplotlib imports are used to plot confusion matrices for the classifiers\n",
        "import matplotlib as mpl \n",
        "import matplotlib.cm as cm \n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "#import feature extraction methods from sklearn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction import stop_words\n",
        "\n",
        "#pre-processing of text\n",
        "import string\n",
        "import re\n",
        "\n",
        "#import classifiers from sklearn\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "#import different metrics to evaluate the classifiers\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.cross_validation import train_test_split\n",
        "from sklearn.metrics import confusion_matrix \n",
        "\n",
        "#import time function from time module to track the training duration\n",
        "from time import time"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-bb92470620a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#import different metrics to evaluate the classifiers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.cross_validation'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuSgt1jJ5xWt",
        "colab_type": "text"
      },
      "source": [
        "### Section 1: Load and explore the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZkcGcXp9wq1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "8facdcff-8fa9-44f9-ec6b-4fd564bafc31"
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 131183 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.13-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.13-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.13-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbED8Q185xWu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "831b227d-0506-4b72-ced8-63a33c5fd853"
      },
      "source": [
        "\n",
        "\n",
        "#our_data = pd.read_csv(\" /home/bangaru/Downloads/NLPBookTut/Full-Economic-News-DFE-839861.csv\", encoding = \"ISO-8859-1\")\n",
        "our_data = pd.read_csv(\"/content/drive/NLP_book/Datasets/practicalnlp-master/Full-Economic-News-DFE-839861.csv\" , encoding = \"ISO-8859-1\" )\n",
        "#our_data.head() #This shows some the first few rows. We need the columns: relevance and text to do text classification\n",
        "our_data.shape #Number of rows (instances) and columns in the dataset\n",
        "our_data[\"relevance\"].value_counts()/our_data.shape[0] #Class distribution in the dataset"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "no          0.821375\n",
              "yes         0.177500\n",
              "not sure    0.001125\n",
              "Name: relevance, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCED1t7F5xW9",
        "colab_type": "text"
      },
      "source": [
        "There is an imbalance in the data with **not relevant** being 82% in the dataset. That is, most of the articles are not relevant to US Economy, which makes sense in a real-world scenario, as news articles discuss various topics. We should keep this class imbalance mind when interpreting the classifier performance later. Let us first convert the class labels into binary outcome variables for convenience. 1 for Yes (relevant), and 0 for No (not relevant), and ignore \"Not sure\". "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYW_S3585xXF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "279dfe81-5c79-4a1f-ebe6-66c14acb9d71"
      },
      "source": [
        "# convert label to a numerical variable\n",
        "our_data = our_data[our_data.relevance != \"not sure\"]\n",
        "our_data.shape\n",
        "our_data['relevance'] = our_data.relevance.map({'yes':1, 'no':0}) #relevant is 1, not-relevant is 0. \n",
        "our_data = our_data[[\"text\",\"relevance\"]] #Let us take only the two columns we need.\n",
        "our_data.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7991, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOKz8xQr5xXJ",
        "colab_type": "text"
      },
      "source": [
        "### Section 3: Text Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhC5TZuL5xXK",
        "colab_type": "text"
      },
      "source": [
        "Typical steps involve tokenization, lower casing, removing, stop words, punctuation markers etc, and vectorization. Other processes such as stemming/lemmatization can also be performed. Here, we are performing the following steps: removing br tags, punctuation, numbers, and stopwords. While we are using sklearn's list of stopwords, there are several other stop word lists (e.g., from NLTK) or sometimes, custom stopword lists are needed depending on the task. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MZSHdHZ5xXL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopwords = stop_words.ENGLISH_STOP_WORDS\n",
        "def clean(doc): #doc is a string of text\n",
        "    doc = doc.replace(\"</br>\", \" \") #This text contains a lot of <br/> tags.\n",
        "    doc = \"\".join([char for char in doc if char not in string.punctuation and not char.isdigit()])\n",
        "    doc = \" \".join([token for token in doc.split() if token not in stopwords])\n",
        "    #remove punctuation and numbers\n",
        "    return doc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CfVm42o5xXS",
        "colab_type": "text"
      },
      "source": [
        "### Section 3: Modeling\n",
        "\n",
        "Now we are ready for the modelling. We are going to use algorithms from sklearn package. We will go through the following steps:\n",
        "\n",
        "1 Split the data into training and test sets (75% train, 25% test)    \n",
        "2 Extract features from the training data using CountVectorizer, which is a bag of words feature  implementation. We will use the pre-processing function above in conjunction with Count Vectorizer  \n",
        "3 Transform the test data into the same feature vector as the training data.  \n",
        "4 Train the classifier  \n",
        "5 Evaluate the classifier  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GimJJHhg5xYl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "489b990b-e6a0-45d4-958f-6d98074c1333"
      },
      "source": [
        "import sklearn\n",
        "#from sklearn.cross_validation import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Step 1: train-test split\n",
        "X = our_data.text #the column text contains textual data to extract features from\n",
        "y = our_data.relevance #this is the column we are learning to predict. \n",
        "print(X.shape, y.shape)\n",
        "# split X and y into training and testing sets. By default, it splits 75% training and 25% test\n",
        "#random_state=1 for reproducibility\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7991,) (7991,)\n",
            "(5993,) (5993,)\n",
            "(1998,) (1998,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsUyIBUD5xZI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "686622b6-3bb8-48fb-917f-696ca74f557a"
      },
      "source": [
        "#Step 2-3: Preprocess and Vectorize train and test data\n",
        "vect = CountVectorizer(preprocessor=clean) #instantiate a vectoriezer\n",
        "X_train_dtm = vect.fit_transform(X_train)#use it to extract features from training data\n",
        "#transform testing data (using training data's features)\n",
        "X_test_dtm = vect.transform(X_test)\n",
        "print(X_train_dtm.shape, X_test_dtm.shape)\n",
        "#i.e., the dimension of our feature vector is 49753!"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5993, 49753) (1998, 49753)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDLwA4CL5xZq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e7c816f0-3245-4e6c-fe93-2b281f93e7d7"
      },
      "source": [
        "#Step 3: Train the classifier and predict for test data\n",
        "nb = MultinomialNB() #instantiate a Multinomial Naive Bayes model\n",
        "%time nb.fit(X_train_dtm, y_train)#train the model(timing it with an IPython \"magic command\")\n",
        "y_pred_class = nb.predict(X_test_dtm)#make class predictions for X_test_dtm"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 17.8 ms, sys: 75 µs, total: 17.9 ms\n",
            "Wall time: 17.6 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiCHjvc75xZ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "314275d0-daeb-4664-a1e1-e02c07137650"
      },
      "source": [
        "#Step 4: Evaluate the classifier using various measures\n",
        "\n",
        "# Function to plot confusion matrix. \n",
        "# Ref:http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "import itertools\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label',fontsize=15)\n",
        "    plt.xlabel('Predicted label',fontsize=15)\n",
        "    \n",
        "    \n",
        "#Print accuracy:\n",
        "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred_class))\n",
        "\n",
        "    \n",
        "# print the confusion matrix\n",
        "cnf_matrix = confusion_matrix(y_test, y_pred_class)\n",
        "plt.figure(figsize=(8,6))\n",
        "plot_confusion_matrix(cnf_matrix, classes=['Not Relevant','Relevant'],normalize=True,\n",
        "                      title='Confusion matrix with all features')\n",
        "\n",
        "# calculate AUC: Area under the curve(AUC) gives idea about the model efficiency:\n",
        "#Further information: https://en.wikipedia.org/wiki/Receiver_operating_characteristic\n",
        "y_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\n",
        "print(\"ROC_AOC_Score: \", metrics.roc_auc_score(y_test, y_pred_prob))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-476aa7a6d755>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#Print accuracy:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ga5-KhYN5xaD",
        "colab_type": "text"
      },
      "source": [
        "At this point, we can notice that the classifier is doing poorly with identifying relevant articles, while it is doing well with non-relevant ones. Our large feature vector could be creating a lot of noise in the form of very rarely occurring features that are not useful for learning. Let us change the count vectorizer to take a certain number of features as maximum. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylOI4OsD5xaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vect = CountVectorizer(preprocessor=clean, max_features=5000) #Step-1\n",
        "X_train_dtm = vect.fit_transform(X_train)#combined step 2 and 3\n",
        "X_test_dtm = vect.transform(X_test)\n",
        "nb = MultinomialNB() #instantiate a Multinomial Naive Bayes model\n",
        "%time nb.fit(X_train_dtm, y_train)#train the model(timing it with an IPython \"magic command\")\n",
        "y_pred_class = nb.predict(X_test_dtm)#make class predictions for X_test_dtm\n",
        "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred_class))\n",
        "# print the confusion matrix\n",
        "cnf_matrix = confusion_matrix(y_test, y_pred_class)\n",
        "plt.figure(figsize=(8,6))\n",
        "plot_confusion_matrix(cnf_matrix, classes=['Not Relevant','Relevant'],normalize=True,\n",
        "                      title='Confusion matrix with max 5000 features')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JzJ6k7g5xaL",
        "colab_type": "text"
      },
      "source": [
        "Clearly, the performance on relevance classification got better even though the overall accuracy fell by 10%. Let us try another classification algorithm and see if the performance changes. For this experiment, we have considered logistic regression, with class_weight attribute as \"balanced\", to address the problem of class imbalance in this dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v7pM9hB5xbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression #import\n",
        "\n",
        "logreg = LogisticRegression(class_weight=\"balanced\") #instantiate a logistic regression model\n",
        "logreg.fit(X_train_dtm, y_train) #fit the model with training data\n",
        "\n",
        "#Make predictions on test data\n",
        "y_pred_class = logreg.predict(X_test_dtm)\n",
        "\n",
        "#calculate evaluation measures:\n",
        "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred_class))\n",
        "print(\"AUC: \", metrics.roc_auc_score(y_test, y_pred_prob))\n",
        "cnf_matrix = confusion_matrix(y_test, y_pred_class)\n",
        "plt.figure(figsize=(8,6))\n",
        "plot_confusion_matrix(cnf_matrix, classes=['Not Relevant','Relevant'],normalize=True,\n",
        "                      title='Confusion matrix with normalization')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v1evQyy5xbe",
        "colab_type": "text"
      },
      "source": [
        "Let us wrap this notebook by trying with one more classifier, but reducing the feature vector size to 1000."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJLKusAQ5xbf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "vect = CountVectorizer(preprocessor=clean, max_features=1000) #Step-1\n",
        "X_train_dtm = vect.fit_transform(X_train)#combined step 2 and 3\n",
        "X_test_dtm = vect.transform(X_test)\n",
        "\n",
        "classifier = LinearSVC(class_weight='balanced') #instantiate a logistic regression model\n",
        "classifier.fit(X_train_dtm, y_train) #fit the model with training data\n",
        "\n",
        "#Make predictions on test data\n",
        "y_pred_class = classifier.predict(X_test_dtm)\n",
        "\n",
        "#calculate evaluation measures:\n",
        "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred_class))\n",
        "print(\"AUC: \", metrics.roc_auc_score(y_test, y_pred_prob))\n",
        "cnf_matrix = confusion_matrix(y_test, y_pred_class)\n",
        "plt.figure(figsize=(8,6))\n",
        "plot_confusion_matrix(cnf_matrix, classes=['Not Relevant','Relevant'],normalize=True,\n",
        "                      title='Confusion matrix with normalization')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd_-M70F5xbl",
        "colab_type": "text"
      },
      "source": [
        "So, how do we choose whats the best? If we look at overall accuracy alone, we should be choosing the very first classifier in this notebook. However, that is also doing poorly with identifying \"relevant\" articles. If we choose purely based on how good it is doing with \"relevant\" category, we should choose the second one we built. If we choose purely based on how good it is doing with \"irrelevant\" category, surely, nothing beats not building any classifier and just calling everything irrelevant! So, what to choose as the best among these depends on what we are looking for in our usecase! "
      ]
    }
  ]
}
