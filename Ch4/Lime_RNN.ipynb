{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lime.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiGdNSat-V2i",
        "colab_type": "code",
        "outputId": "d3287351-5cb3-483b-a56e-54bade7d50d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "\n",
        "!wget -P /root/input/ -c \"http://nlp.stanford.edu/data/glove.6B.zip\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-12 09:01:31--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-03-12 09:01:31--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-03-12 09:01:31--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘/root/input/glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.05MB/s    in 6m 28s  \n",
            "\n",
            "2020-03-12 09:07:59 (2.12 MB/s) - ‘/root/input/glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsCn1xlo_MMX",
        "colab_type": "code",
        "outputId": "a5f0393a-0812-4fd0-c593-1479a8a6ed76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def load_directory_data(directory):\n",
        "  data = {}\n",
        "  data[\"sentence\"] = []\n",
        "  data[\"sentiment\"] = []\n",
        "  for file_path in os.listdir(directory):\n",
        "    with tf.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
        "      data[\"sentence\"].append(f.read())\n",
        "      data[\"sentiment\"].append(re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n",
        "  return pd.DataFrame.from_dict(data)\n",
        "\n",
        "# Merge positive and negative examples, add a polarity column and shuffle.\n",
        "def load_dataset(directory):\n",
        "  pos_df = load_directory_data(os.path.join(directory, \"pos\"))\n",
        "  neg_df = load_directory_data(os.path.join(directory, \"neg\"))\n",
        "  pos_df[\"polarity\"] = 1\n",
        "  neg_df[\"polarity\"] = 0\n",
        "  return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "def download_and_load_datasets(force_download=False):\n",
        "  dataset = tf.keras.utils.get_file(\n",
        "      fname=\"aclImdb.tar.gz\", \n",
        "      origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
        "      extract=True)\n",
        "  \n",
        "  train_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
        "                                       \"aclImdb\", \"train\"))\n",
        "  test_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
        "                                      \"aclImdb\", \"test\"))\n",
        "  \n",
        "  return train_df, test_df\n",
        "\n",
        "train,test = download_and_load_datasets()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84131840/84125825 [==============================] - 8s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEpQWHnF-hOX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding, LSTM\n",
        "from keras.models import Model, Sequential\n",
        "from keras.initializers import Constant\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 1000\n",
        "MAX_NUM_WORDS = 20000 \n",
        "EMBEDDING_DIM = 100 \n",
        "VALIDATION_SPLIT = 0.2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "830AVGaZBfnf",
        "colab_type": "code",
        "outputId": "c5fdd29a-b8fe-44a1-d81e-ddb0f1c57be0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['sentence', 'sentiment', 'polarity'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJo_FLISBhx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_texts = train['sentence'].values\n",
        "train_labels = train['polarity'].values\n",
        "test_texts = test['sentence'].values\n",
        "# test_labels = test['polarity'].values\n",
        "\n",
        "labels_index = {'pos':1, 'neg':0} "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZ1G3DH3dDQ4",
        "colab_type": "code",
        "outputId": "8d6a5449-9d67-4ab5-d984-4eb80c971c4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test.columns\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['sentence', 'sentiment', 'polarity'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8I6QgXldKd0",
        "colab_type": "code",
        "outputId": "e251c62f-451f-48cb-cce1-e46bd5dd9796",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_labels = test['polarity'].values\n",
        "test_labels"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XPvvoKGBoa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-GTC5ZFB8cm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1F-Kq4Z0Kyxo",
        "colab_type": "code",
        "outputId": "bbb8e477-6957-4ee9-fdeb-24924ff2ab7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLFPxzSfCyLS",
        "colab_type": "code",
        "outputId": "3565f138-c551-441a-951c-16e0cdf59411",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Defining and training an LSTM model, training embedding layer on the fly\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defining and training an LSTM model, training embedding layer on the fly\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGfRWIK9KBkO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFxZJhpnC4fV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MumrzNJtMTKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 20000  # Max number of different word, i.e. model input dimension\n",
        "maxlen = 1000 # Max number of words kept at the end of each text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibekacAMMTsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.pipeline import TransformerMixin\n",
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "class TextsToSequences(Tokenizer, BaseEstimator, TransformerMixin):\n",
        "    \"\"\" Sklearn transformer to convert texts to indices list \n",
        "    (e.g. [[\"the cute cat\"], [\"the dog\"]] -> [[1, 2, 3], [1, 4]])\"\"\"\n",
        "    def __init__(self,  **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        \n",
        "    def fit(self, texts, y=None):\n",
        "        self.fit_on_texts(texts)\n",
        "        return self\n",
        "    \n",
        "    def transform(self, texts, y=None):\n",
        "        return np.array(self.texts_to_sequences(texts))\n",
        "        \n",
        "sequencer = TextsToSequences(num_words=vocab_size)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Padder(BaseEstimator, TransformerMixin):\n",
        "    \"\"\" Pad and crop uneven lists to the same length. \n",
        "    Only the end of lists longernthan the maxlen attribute are\n",
        "    kept, and lists shorter than maxlen are left-padded with zeros\n",
        "    \n",
        "    Attributes\n",
        "    ----------\n",
        "    maxlen: int\n",
        "        sizes of sequences after padding\n",
        "    max_index: int\n",
        "        maximum index known by the Padder, if a higher index is met during \n",
        "        transform it is transformed to a 0\n",
        "    \"\"\"\n",
        "    def __init__(self, maxlen=500):\n",
        "        self.maxlen = maxlen\n",
        "        self.max_index = None\n",
        "        \n",
        "    def fit(self, X, y=None):\n",
        "        self.max_index = pad_sequences(X, maxlen=self.maxlen).max()\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X, y=None):\n",
        "        X = pad_sequences(X, maxlen=self.maxlen)\n",
        "        X[X > self.max_index] = 0\n",
        "        return X\n",
        "\n",
        "padder = Padder(maxlen)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XvXEYGBMWlW",
        "colab_type": "code",
        "outputId": "a546a0c7-169a-4ca9-fb0d-c054250f740a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, Bidirectional, LSTM\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "batch_size = 64\n",
        "max_features = vocab_size + 1\n",
        "\n",
        "def create_model(max_features):\n",
        "    \"\"\" Model creation function: returns a compiled LSTM\"\"\"\n",
        "\n",
        "\n",
        "    rnnmodel = Sequential()\n",
        "    rnnmodel.add(Embedding(MAX_NUM_WORDS, 128))\n",
        "    rnnmodel.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "    rnnmodel.add(Dense(1, activation='sigmoid'))\n",
        "    rnnmodel.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "    return rnnmodel\n",
        "\n",
        "\n",
        "# Use Keras Scikit-learn wrapper to instantiate a LSTM with all methods\n",
        "# required by Scikit-learn for the last step of a Pipeline\n",
        "sklearn_lstm = KerasClassifier(build_fn=create_model, epochs=2, batch_size=32, \n",
        "                               max_features=max_features, verbose=1)\n",
        "\n",
        "# Build the Scikit-learn pipeline\n",
        "pipeline = make_pipeline(sequencer, padder, sklearn_lstm)\n",
        "\n",
        "pipeline.fit(train_texts, train_labels);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "25000/25000 [==============================] - 1486s 59ms/step - loss: 0.5025 - acc: 0.7597\n",
            "Epoch 2/2\n",
            "25000/25000 [==============================] - 1475s 59ms/step - loss: 0.3441 - acc: 0.8572\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eormsftYNGZk",
        "colab_type": "code",
        "outputId": "7b1c6a9b-4d9c-4405-b0ef-296ead1522e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "print('Computing predictions on test set...')\n",
        "y_preds = pipeline.predict(test_texts)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computing predictions on test set...\n",
            "25000/25000 [==============================] - 312s 12ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-7571fbdf55de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy: {:.2f} %'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 90\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and multilabel-indicator targets"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KKnIf5BcnQn",
        "colab_type": "code",
        "outputId": "bef294a5-b7bb-4b60-812b-91f843b8a04b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Test accuracy: {:.2f} %'.format(100*metrics.accuracy_score(y_preds, test_labels)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 83.70 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jd9mzgXrZ9ys",
        "colab_type": "code",
        "outputId": "9a640266-ef6d-40cc-8d6c-07023424b69c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        }
      },
      "source": [
        "\n",
        "\n",
        "# We choose a sample from test set\n",
        "idx = 11\n",
        "text_sample = test_texts[idx]\n",
        "class_names = ['negative', 'positive']\n",
        "\n",
        "print('Sample {}: last 1000 words (only part used by the model)'.format(idx))\n",
        "print('-'*50)\n",
        "print(\" \".join(text_sample.split()[-1000:]))\n",
        "print('-'*50)\n",
        "print('Probability(positive) =', pipeline.predict_proba([text_sample])[0,1])\n",
        "print('True class: %s' % class_names[test_labels[idx]])\n",
        "\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from collections import OrderedDict\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "\n",
        "explainer = LimeTextExplainer(class_names=class_names)\n",
        "explanation = explainer.explain_instance(text_sample, pipeline.predict_proba, num_features=10)\n",
        "\n",
        "weights = OrderedDict(explanation.as_list())\n",
        "lime_weights = pd.DataFrame({'words': list(weights.keys()), 'weights': list(weights.values())})\n",
        "\n",
        "sns.barplot(x=\"words\", y=\"weights\", data=lime_weights);\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Sample {} features weights given by LIME'.format(idx));"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample 11: last 1000 words (only part used by the model)\n",
            "--------------------------------------------------\n",
            "The film starts out with a narration of the protagonist explaining certain crimes occurring all over the city and then we get to know that the hero is a cop who is either suspended or has probably retired. I did not have the patience or the interest to verify the above before commenting. If there is a stereotype for narrators to have a deep, sleep-inducing voice then, it is high time to put an end to it. I seriously fell asleep and did not bother to shut the movie down either. Am still trying to figure out what the movie was all about and why there were no outdoor shootings. A third rate TV Serial will have more number of sets compared to this crap of a movie and I still pity the actors and producers involved in this huge bullshit of a movie. It ought to have been produced as a normal TV serial or maybe even as a local theater drama instead of putting it out on the big screen. Total waste of time and money. The movie was supposed to be in production for a long time and it would have been better to have left it that way.With redundant sleep inducing dialogs and sets, this is the worst movie I have come across.\n",
            "--------------------------------------------------\n",
            "1/1 [==============================] - 0s 347ms/step\n",
            "Probability(positive) = 0.07630403\n",
            "True class: negative\n",
            "5000/5000 [==============================] - 63s 13ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEtCAYAAAAm6zZnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3JGXJF2aIFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}